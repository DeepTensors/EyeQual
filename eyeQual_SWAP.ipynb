{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "# sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, MaxPooling2D, AveragePooling2D, Activation, Input, Flatten, concatenate, GlobalAveragePooling2D, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras import initializers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedAveragePooling(Layer):\n",
    "    def __init__(self, output_shape, **kwargs):\n",
    "        self.shape = output_shape\n",
    "        super(WeightedAveragePooling, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(name='W1', shape=self.shape, initializer='uniform') # creating W\n",
    "\n",
    "        super(WeightedAveragePooling, self).build(input_shape)\n",
    "\n",
    "    def call(self, input_):\n",
    "        w_absolute = K.abs(self.w)  # making w values positive\n",
    "        numerator = input_*w_absolute\n",
    "        numerator_sum = K.expand_dims(K.sum(numerator, axis=(1, 2, 3)))\n",
    "        denominator = K.sum(w_absolute, axis=(1, 2, 3))\n",
    "        denominator_sum = K.expand_dims(K.sum(w_absolute, axis=(1, 2, 3)))\n",
    "        return numerator_sum / (denominator_sum + 1e-7)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], 1)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'shape': self.shape,\n",
    "        }\n",
    "        base_config = super(WeightedAveragePooling, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SWAP(Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(SWAP, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        # print(input_shape[-1], self.output_shape_)\n",
    "        input_dim = input_shape[-1]\n",
    "        print(type(input_dim))\n",
    "\n",
    "        self.w = self.add_weight(name='w', shape=(input_dim, self.output_dim), initializer='uniform')\n",
    "        super(SWAP, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        w_ = np.abs(self.w)\n",
    "        self.w = self.w/(np.sum(w_) + 1e-7)\n",
    "        x = K.dot(inputs, K.abs(self.w))          # weights need to be non negative\n",
    "        bias_ = -0.5*np.ones(1,)\n",
    "        output = x + bias_\n",
    "        output = Activation('sigmoid')(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = list(input_shape)\n",
    "        shape[-1] = self.output_dim\n",
    "        return tuple(shape)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'output_dim': self.output_dim\n",
    "                 }\n",
    "        base_config = super(SWAP, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyeCalc:\n",
    "    def __init__(self, input_):\n",
    "        self.input = input_\n",
    "\n",
    "    def convolution(self, input_, kernel_size, filters, strides=1, activation='relu', max_pool=\"True\", batch_norm=\"True\"):\n",
    "\n",
    "        x = Conv2D(kernel_size=kernel_size, filters=filters, strides=strides, padding='same')(input_)\n",
    "\n",
    "        if activation == 'sigmoid':\n",
    "            x = Activation('sigmoid')(x)\n",
    "        else:\n",
    "            x = Activation('relu')(x)\n",
    "            #x = LeakyReLU(0.03)(x)\n",
    "\n",
    "        if batch_norm:\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "        if max_pool:\n",
    "            x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def conv2d(self):\n",
    "        num_filters = 64\n",
    "        x = self.convolution(self.input, 3, num_filters, strides=1)\n",
    "        for i in range(3):\n",
    "            num_filters *= 2\n",
    "            x = self.convolution(x, 3, num_filters, strides=1)\n",
    "        ### check###\n",
    "\n",
    "        # x = self.convolution(x, kernel_size=1, filters=num_filters, strides=1, activation='sigmoid', max_pool=False,\n",
    "        #                      batch_norm=False)\n",
    "        x = self.convolution(x, kernel_size=1, filters=1, strides=1, activation='sigmoid', max_pool=False, batch_norm=False)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def pooling(self, input_, type='wap'):\n",
    "        if type == 'swap':\n",
    "            x = Flatten()(input_)\n",
    "            x = SWAP(1)(x)\n",
    "\n",
    "        else:\n",
    "            x = WeightedAveragePooling((1, 31, 31, 1))(input_)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self):\n",
    "        x = self.conv2d()\n",
    "        x = self.pooling(x, type='swap')\n",
    "\n",
    "        return x\n",
    "\n",
    "    def build_model(self):\n",
    "\n",
    "        output = self.forward()\n",
    "        model = Model(self.input, output)\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/home/Sudhakar/Desktop/'\n",
    "imgs_path_good = glob.glob(os.path.join(dir, 'Good/*.jpg'))\n",
    "# print(np.shape(imgs_path_good))\n",
    "imgs_path_bad = glob.glob(os.path.join(dir, 'Bad/*.jpg'))\n",
    "# print(np.shape(imgs_path_bad))\n",
    "images_good= []\n",
    "images_bad = []\n",
    "labels_good = []\n",
    "labels_bad = []\n",
    "\n",
    "img_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing(image):\n",
    "    img = image\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def read_imgs(image_path, good=True):\n",
    "    image_array = []\n",
    "    label_array = []\n",
    "    for image in image_path:\n",
    "        img = plt.imread(image)\n",
    "        image_array.append(image_preprocessing(img))\n",
    "        if good:\n",
    "            label_array.append(0)\n",
    "        else:\n",
    "            label_array.append(1)\n",
    "\n",
    "    return image_array, label_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images_good, labels_good = read_imgs(imgs_path_good)\n",
    "images_bad, labels_bad = read_imgs(imgs_path_bad, good=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = images_good + images_bad\n",
    "Y = labels_good + labels_bad\n",
    "# print(np.shape(X), np.shape(Y))\n",
    "X_final = np.reshape(X, (np.shape(X)[0], np.shape(X)[1], np.shape(X)[2], 3))\n",
    "Y_final = np.reshape(Y, (np.shape(Y)[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_final, Y_final, test_size=0.3)\n",
    "x_val, x_test2, y_val, y_test_2 = train_test_split(x_test, y_test, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 512, 512, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True,\n",
    "        rotation_range=20,\n",
    "        rescale=1./255\n",
    "        #width_shift_range=0.1,\n",
    "        #height_shift_range=0.1\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "#datagen.fit(x_test)\n",
    "#datagen.fit(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('model_512-{epoch:03d}.h5',\n",
    "                                monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 512, 512, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 512, 512, 64)      1792      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512, 512, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_4 (Ba (None, 512, 512, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 256, 256, 128)     73856     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 256, 256, 128)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_5 (Ba (None, 256, 256, 128)     512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 256)     295168    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128, 128, 256)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_6 (Ba (None, 128, 128, 256)     1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 64, 64, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 64, 64, 512)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_7 (Ba (None, 64, 64, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 1)         513       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "swap_1 (SWAP)                (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,555,329\n",
      "Trainable params: 1,553,409\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "obj = EyeCalc(Input(shape=(img_size, img_size, 3)))\n",
    "model = obj.build_model()\n",
    "model.summary()\n",
    "optimizer = Adam(lr=0.001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "199/200 [============================>.] - ETA: 0s - loss: 9.8460 - accuracy: 0.4534\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.72340, saving model to model_512-001.h5\n",
      "200/200 [==============================] - 132s 662ms/step - loss: 9.7993 - accuracy: 0.4550 - val_loss: 0.6031 - val_accuracy: 0.7234\n",
      "Epoch 2/10\n",
      "199/200 [============================>.] - ETA: 0s - loss: 4.6337 - accuracy: 0.5754\n",
      "Epoch 00002: val_accuracy did not improve from 0.72340\n",
      "200/200 [==============================] - 141s 705ms/step - loss: 4.6107 - accuracy: 0.5760 - val_loss: 45.9736 - val_accuracy: 0.2766\n",
      "Epoch 3/10\n",
      "199/200 [============================>.] - ETA: 0s - loss: 2.6388 - accuracy: 0.5985\n",
      "Epoch 00003: val_accuracy did not improve from 0.72340\n",
      "200/200 [==============================] - 133s 663ms/step - loss: 2.6287 - accuracy: 0.5983 - val_loss: 0.6518 - val_accuracy: 0.6596\n",
      "Epoch 4/10\n",
      "199/200 [============================>.] - ETA: 0s - loss: 1.1023 - accuracy: 0.6564\n",
      "Epoch 00004: val_accuracy did not improve from 0.72340\n",
      "200/200 [==============================] - 133s 665ms/step - loss: 1.0997 - accuracy: 0.6559 - val_loss: 0.6142 - val_accuracy: 0.7021\n",
      "Epoch 5/10\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.8070 - accuracy: 0.6654\n",
      "Epoch 00005: val_accuracy did not improve from 0.72340\n",
      "200/200 [==============================] - 131s 655ms/step - loss: 0.8057 - accuracy: 0.6652 - val_loss: 0.6031 - val_accuracy: 0.7234\n",
      "Epoch 6/10\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.6648 - accuracy: 0.7289\n",
      "Epoch 00006: val_accuracy did not improve from 0.72340\n",
      "200/200 [==============================] - 136s 679ms/step - loss: 0.6643 - accuracy: 0.7297 - val_loss: 0.6031 - val_accuracy: 0.7234\n",
      "Epoch 7/10\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.5495 - accuracy: 0.8114\n",
      "Epoch 00007: val_accuracy did not improve from 0.72340\n",
      "200/200 [==============================] - 134s 672ms/step - loss: 0.5492 - accuracy: 0.8117 - val_loss: 0.6031 - val_accuracy: 0.7234\n",
      "Epoch 8/10\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.5307 - accuracy: 0.8179\n",
      "Epoch 00008: val_accuracy did not improve from 0.72340\n",
      "200/200 [==============================] - 132s 662ms/step - loss: 0.5302 - accuracy: 0.8176 - val_loss: 0.6031 - val_accuracy: 0.7234\n",
      "Epoch 9/10\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.4700 - accuracy: 0.8694\n",
      "Epoch 00009: val_accuracy did not improve from 0.72340\n",
      "200/200 [==============================] - 133s 664ms/step - loss: 0.4696 - accuracy: 0.8701 - val_loss: 0.5990 - val_accuracy: 0.7234\n",
      "Epoch 10/10\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.4602 - accuracy: 0.8851\n",
      "Epoch 00010: val_accuracy did not improve from 0.72340\n",
      "200/200 [==============================] - 134s 669ms/step - loss: 0.4605 - accuracy: 0.8847 - val_loss: 0.6031 - val_accuracy: 0.7234\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    epochs=epochs, validation_data=(x_val, y_val), callbacks=callbacks_list, steps_per_epoch=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "12/12 [==============================] - 1s 78ms/sample - loss: 0.5991 - accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "y_evaluted = model.evaluate(x_test2, y_test_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
