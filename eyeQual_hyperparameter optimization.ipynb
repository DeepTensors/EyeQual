{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "import cv2\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, MaxPooling2D, AveragePooling2D, Activation, Input, Flatten, concatenate, GlobalAveragePooling2D, LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer, InputSpec\n",
    "from keras import initializers\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from visualize_activations import VisualizeActivation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedAveragePooling(Layer):\n",
    "    def __init__(self, output_shape, **kwargs):\n",
    "        self.shape = output_shape\n",
    "        super(WeightedAveragePooling, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(name='W1', shape=self.shape, initializer='uniform') # creating W\n",
    "\n",
    "        super(WeightedAveragePooling, self).build(input_shape)\n",
    "\n",
    "    def call(self, input_):\n",
    "        w_absolute = K.abs(self.w)  # making w values positive\n",
    "        numerator = input_*w_absolute\n",
    "        numerator_sum = K.expand_dims(K.sum(numerator, axis=(1, 2, 3)))\n",
    "        denominator = K.sum(w_absolute, axis=(1, 2, 3))\n",
    "        denominator_sum = K.expand_dims(K.sum(w_absolute, axis=(1, 2, 3)))\n",
    "        return numerator_sum / (denominator_sum + 1e-7)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], 1)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'shape': self.shape,\n",
    "        }\n",
    "        base_config = super(WeightedAveragePooling, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SWAP(Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(SWAP, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        # print(input_shape[-1], self.output_shape_)\n",
    "        input_dim = input_shape[-1]\n",
    "        print(type(input_dim))\n",
    "\n",
    "        self.w = self.add_weight(name='w', shape=(input_dim, self.output_dim), initializer='glorot_normal')\n",
    "        super(SWAP, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        w_ = np.abs(self.w)\n",
    "        self.w = self.w/(np.sum(w_))\n",
    "        x = K.dot(inputs, K.abs(self.w))          # weights need to be non negative\n",
    "        bias_ = -0.5*np.ones(1,)\n",
    "        output = x + bias_\n",
    "        output = Activation('sigmoid')(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = list(input_shape)\n",
    "        shape[-1] = self.output_dim\n",
    "        return tuple(shape)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'output_dim': self.output_dim\n",
    "                 }\n",
    "        base_config = super(SWAP, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyeCalc:\n",
    "    def __init__(self, input_):\n",
    "        self.input = input_\n",
    "\n",
    "    def convolution(self, input_, kernel_size, filters, strides=1, activation='relu', max_pool=\"True\", batch_norm=\"True\"):\n",
    "\n",
    "        x = Conv2D(kernel_size=kernel_size, filters=filters, strides=strides, padding='same')(input_)\n",
    "\n",
    "        if activation == 'sigmoid':\n",
    "            x = Activation('sigmoid')(x)\n",
    "        else:\n",
    "            x = Activation('relu')(x)\n",
    "#             x = LeakyReLU(0.02)(x)\n",
    "\n",
    "        if batch_norm:\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "        if max_pool:\n",
    "            x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def conv2d(self):\n",
    "        num_filters = 64\n",
    "        x = self.convolution(self.input, 3, num_filters, strides=1)\n",
    "        for i in range(3):\n",
    "            num_filters *= 2\n",
    "            x = self.convolution(x, 3, num_filters, strides=1)\n",
    "    \n",
    "        x = self.convolution(x, kernel_size=1, filters=1, strides=1, activation='sigmoid', max_pool=False, batch_norm=False)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def pooling(self, input_, type='wap'):\n",
    "        if type == 'swap':\n",
    "            x = Flatten()(input_)\n",
    "            x = SWAP(1)(x)\n",
    "\n",
    "        else:\n",
    "            x = WeightedAveragePooling((1, 31, 31, 1))(input_)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self):\n",
    "        x = self.conv2d()\n",
    "        x = self.pooling(x, type='swap')\n",
    "\n",
    "        return x\n",
    "\n",
    "    def build_model(self):\n",
    "\n",
    "        output = self.forward()\n",
    "        model = Model(self.input, output)\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/home/hitech/Downloads/DRIMDB/'\n",
    "imgs_path_good = glob.glob(os.path.join(dir, 'Good/*.jpg'))\n",
    "# print(np.shape(imgs_path_good))\n",
    "imgs_path_bad = glob.glob(os.path.join(dir, 'Bad/*.jpg'))\n",
    "# print(np.shape(imgs_path_bad))\n",
    "images_good= []\n",
    "images_bad = []\n",
    "labels_good = []\n",
    "labels_bad = []\n",
    "\n",
    "img_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing(image):\n",
    "    img = cv2.resize(image, (img_size, img_size))\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def read_imgs(image_path, good=True):\n",
    "    image_array = []\n",
    "    label_array = []\n",
    "    for image in image_path:\n",
    "        img = plt.imread(image)\n",
    "        image_array.append(image_preprocessing(img))\n",
    "        if good:\n",
    "            label_array.append(0)\n",
    "        else:\n",
    "            label_array.append(1)\n",
    "\n",
    "    return image_array, label_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images_good, labels_good = read_imgs(imgs_path_good)\n",
    "images_bad, labels_bad = read_imgs(imgs_path_bad, good=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = images_good + images_bad\n",
    "Y = labels_good + labels_bad\n",
    "# print(np.shape(X), np.shape(Y))\n",
    "X_final = np.reshape(X, (np.shape(X)[0], np.shape(X)[1], np.shape(X)[2], 3))\n",
    "Y_final = np.reshape(Y, (np.shape(Y)[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_final, Y_final, test_size=0.3)\n",
    "x_val, x_test2, y_val, y_test_2 = train_test_split(x_test, y_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True,\n",
    "        rotation_range=20,\n",
    "        rescale=1/255.0\n",
    "#         width_shift_range=0.1,\n",
    "#         height_shift_range=0.1\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "# datagen.fit(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights.eyeQual.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hitech/dl_env_3.5/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "<class 'numpy.int64'>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 1)           513       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 1)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "swap_1 (SWAP)                (None, 1)                 64        \n",
      "=================================================================\n",
      "Total params: 1,555,393\n",
      "Trainable params: 1,553,473\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "obj = EyeCalc(Input(shape=(img_size, img_size, 3)))\n",
    "model = obj.build_model()\n",
    "model.summary()\n",
    "optimizer = Adam(lr=0.001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hitech/dl_env_3.5/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 157s 2s/step - loss: 9.8216 - acc: 0.3837 - val_loss: 0.6181 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.71186, saving model to weights.eyeQual.hdf5\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 181s 2s/step - loss: 2.5266 - acc: 0.5586 - val_loss: 0.5356 - val_acc: 0.7966\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.71186 to 0.79661, saving model to weights.eyeQual.hdf5\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 187s 2s/step - loss: 0.8356 - acc: 0.6279 - val_loss: 0.5441 - val_acc: 0.7797\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.79661\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 189s 2s/step - loss: 0.6158 - acc: 0.7475 - val_loss: 0.6018 - val_acc: 0.7288\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.79661\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 185s 2s/step - loss: 0.6613 - acc: 0.6561 - val_loss: 0.6181 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.79661\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 186s 2s/step - loss: 0.6272 - acc: 0.6927 - val_loss: 0.6016 - val_acc: 0.7288\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.79661\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 177s 2s/step - loss: 0.6155 - acc: 0.6914 - val_loss: 0.5851 - val_acc: 0.7458\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.79661\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 148s 1s/step - loss: 0.6430 - acc: 0.6932 - val_loss: 0.6016 - val_acc: 0.7288\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.79661\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 150s 1s/step - loss: 0.5875 - acc: 0.7216 - val_loss: 0.6016 - val_acc: 0.7288\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.79661\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 160s 2s/step - loss: 0.6167 - acc: 0.6880 - val_loss: 0.6016 - val_acc: 0.7288\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.79661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f82f852b320>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    epochs=epochs, validation_data=(x_test, y_test), callbacks=callbacks_list, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABShJREFUeJzt3b1yVAUYxvH37CbZhAQ00TiA4lfjqDPegJ2NhaWXoY1X4XV5AzaMjIUWzgji8KWIBMJmj4VVbNiD5NVHf796Z54D7D+bgtl3GMexgCyzf/oBgOmEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4E2prx4vrs7bu4fnNWznN46apmpqqrZsvl/jzXOnSyGvq2dtqmabZ30jVXVK9u/tezcuf6oHtx78tR/tEnhbu4f1JXPvnj2p5pg/1rfu3v7bu+bYH68atv69a2ttq27H/T9ufZev9+2VVX1+Ttftex8+enXa73Or8oQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQaNIXog/LqsWdnm/G37v+uGWnqmp23PuF6E8u9H1J+eODvksGw8Fx29Z7hz+3bVVVvb/4sWVnZ7be36FPXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAg06QTJbFm1c2s8q2c5Zeun+y07VVXDg4dtW1VVy3cvtW2dLNqm6qX9B21bH774fdtWVdWVjZ73yFat1nqdT1wIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwINOl20DhUnWyf1aP8xWq9GyrPw/L6jbatqqpqvB10dHnZtvXJpe/atj7a/bZtq6rqYDYplWc2H4a1XucTFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwJNO0Eyrzq+sN6JhL9reXi+ZaeqauOXw7atqqpHO/O2rWG37wTJYta3Nauxbauqam+207IzX/Oz1CcuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBJp0gqSGP8+QdDi6uN0zVFV7D3tPkAyrvvMZGzcWbVvX3rzYtnX13KW2raqqtzdvt+ys1jyt4hMXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAk06QbLarHp4eXVWz3LK5v2+nynzo922raqqcRjatrbu9W1du9l3guSbF15r26qq+vjczZad0QkS+O8SLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgSadDto2FzV1qu/n9WznHJ883zLTlXV8lbvz69hvfMwz8XiXt/Y0Y2+G0xXL15u26qq2n55UirPbKj1bj35xIVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwziuf6JiGIZbVfXD2T0O/O+9MY7j4dNeNClc4N/Br8oQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQ6A8JBH7wKiggwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABQ5JREFUeJzt3b1uXFUUhuF1Zsb/SYwcY1FYIaKIRBANt8QF0XMv1FDRIFFFAlJBUiSQxIrtmTlUFFNlDmEWfOJ56i2tfSy93i4srWEcxwKyzP7tCwDTCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCLSYdPj0e9y9Od3WXDePrSVd7L4ur3v8em12v+oat+maNy2XbrHbHhy1j3l6/rJvl1fCuc5Pq2L84rUdfffn3bzXB9bf3W+ZUVV18f9M2q6rq6KcXfcN+f9U2avXbs7ZZ3YbHn7XM+e7Hr7c6509lCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCDRtk8FsXfdPrnZ1lw1PT85a5lRVXX/QtzWhqurg3lHbrPlt33aBxScP22at7/RsFvjLm8uTljnrJ9u9pV5cCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCDRp98ZsGOtocburu2wYG7eCrPf6ZlVVrQ/6Pm523LeqY5wPbbNWd3tXkKz2m75t2G6OFxcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCTVpiszdb1eXxy13dZcMPp6uWOVVVb88aFxVV1bDu23szXPbNmt+MbbPG5ifn5m7PwHG+3TkvLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgSatHvjcHZbj45/3dVdNnxz9qhlTlXVOL/TNquq6vre0Dbr7XnfrOrbQFLz675ZVVWrg6Y5e9ud8+JCIOFCIOFCIOFCIOFCIOFCIOFCIOFCIOFCIOFCIOFCIOFCIOFCIOFCIOFCIOFCIOFCIOFCIOFCIOFCIOFCIOFCIOFCIOFCIOFCIOFCoEkrSI5nN/XF0c87usqmB+eft8ypqnp6dtI2q6pqft24guSjVduscX/dNquWjatVqtqeuHFvuz0uXlwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwINGkFydGwrsd7b3Z1lw0PTl60zKmqenJ50Tarqmp4PenH/l7Gw74VJMNiu/UZ/4T5nb7vqqq6d/eqZc7z/e2+y4sLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgSYtsVnUrM7nJ7u6y4ZXy4OWOVVVddv7+2vxpm/e8EffrHXfSqRant/2DauqTx8+a5nzdLHc6pwXFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIN4zhuf3gYnlfVL7u7DvzvfTyO44fvOjQpXOC/wZ/KEEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EOhPlYd7Ts+SNW8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABRFJREFUeJzt3UtuHAUUheFb3eVHHBt3ACtSIIQBICExZAGwC/bAOlgFq4ElMGQGIkEoQs7TMnG6i7FH6YL0DSd837ikU7b6d3t2h2maCsiyeNMvAMwnXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAg0znl4eXJzGs9Wu3qX61vP+v6mLK7apqqqarPXt7Xe79uq/U3f1Lhu26qqOtm7bNl59OCiLs5fDK96bla449mqPvju23/+VjOc/njYslNVdfSw7wNXVfX8dt8fpacft03V5k7Ph7uq6u7t87atqqqvb//csvP9Nz9s9Zx/lSGQcCGQcCGQcCGQcCGQcCGQcCGQcCGQcCGQcCGQcCGQcCGQcCGQcCGQcCGQcCGQcCGQcCGQcCGQcCGQcCGQcCGQcCGQcCHQvEsGy029c3Kxq3e55uTXWa/2r9z86X7bVlXV1VcftW2tj6e2rdVpz2ejquqLW7+3bVVVfXL4R8vOweLlVs/5xoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAs+58rNeLevzkaFfvcs3Zn5ctO1VVL+8/aNuqqhov77ZtTcu+EyTD0Ld1c/yrbauqalmblp2htvsd+saFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQLNuB9V6qM2TvR29ynWPPz1o2amqOlp92bZVVfXk3rJta7jRd4PpncO+ez6Hi6u2raqqxdBzO2hbvnEhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAh0LwTJNNQixc9rZ9/PrTsVFU9+my/bauq6sX767atG8d9Z0FO9vu2DoaXbVtVVavFRcvOWNudOvGNC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4HmnSAZqqZx2tGrXHd1q2fnTZgO+k6Q7I99W8dj47mT5WXbVlXVatlzgmQ5OEECby3hQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQiDhQqBZJ0iGcVPjez2nH5bjdqcYXoerq2XbVlVVTUPb1KZxq9PB4qp1786y57zKXjlBAm8t4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UKgWbeDlstNvXv6fFfvcs3506OWnaqq9cWsX8NrGOy75/O8Dtu2fruxatt6dtr3c1VVfTget+zsD+dbPecbFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIN0zRt//AwPKyqX3b3OvC/d2+aprNXPTQrXOC/wb/KEEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EOhvyXh82UTO+rgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABQJJREFUeJzt3c9SW3UYxvH3QEgItNiqEeu/Vu3G6R14I16P1+CluXSju2p1OoJtkZAc16yaUycvPuPnsz7Mc0L4crJg+A3jOBaQ5eCubwCYTrgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQaDbl4vnBclzO7u/rXm4Z50ctO1VV42xo26qqGofGvcapbd9b1rpVVTXOev7C8OaPl7W5fPXWd21SuMvZ/fp29d2739UE6yfnLTtVVdcP521bVVWb474POtvGX0qvzvte1+tPe/9Ud71at+w8//6Hna7zURkCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCTfqH6OPRUW0+W+3rXm65/HLZslNVdX2v9ySDzn9S3un6Qd/W+vy6b6yqVh9dtOz8frTZ6TpPXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAg06QiS4c1VDT/+tK97ueXk7FnLTlXV69WibauqajtvHGs87eTmdGzbOjm7atuqqnr2wfOWnZ9n652u88SFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQJPODhrHsbZXTWe29B1DU5tl31ZV1c1J34vbTnqH/531g03b1ur0TdtWVdXXJy9adhYHNztd54kLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgSYdUDEcL+rwydN93cstVyeHLTtVVUPfyRlVVbWd922tz/pe3Pxh0/E0VfXo9KJtq6rq6eLXlp3FwXqn6zxxIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIdCkI0g2x4f11zfv7+tebrl6r+8IksO/26aqqmq4aRxbbNumTpd938hPln+2bVVVfTX/rWVnseMPhycuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBJp0BMl2PtTFF5O+5J1tFi0zd2LsO12lhlnfESRnx31HkHw8v2jbqqr6vOmcmnnt9n554kIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UKgaWcHHVZd39/Xrdx2czr2DN2BzaLvtQ2HfVvHs3Xb1odHl21bVVWPZvdado6Glztd54kLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYZx3P2IimEYXlTVL/u7HfjfezyO4+ptF00KF/hv8FEZAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAv0DBF95lSgqwjEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualzing the feature map for good images (only 5 samples) \n",
    "vis_obj = VisualizeActivation(17,model)\n",
    "j = 0\n",
    "for i in imgs_path_good:\n",
    "    if(j==5):\n",
    "        break\n",
    "    else:\n",
    "        j+=1\n",
    "        img_test = plt.imread(i)\n",
    "        img_test = cv2.resize(img_test, (img_size, img_size))\n",
    "        img_test_ = np.reshape(img_test, (1, img_test.shape[0], img_test.shape[1], img_test.shape[2]))\n",
    "        plt.figure(figsize=(4,4))\n",
    "        vis_obj.visualize_feature_maps(img_test_)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABRdJREFUeJzt3U1uWwUUhuFzYzt2cNKGtpGqCrWTDhBbQarYGXtgCSyBEWIBwACBOmIQfirSUCexfRlnFBvIgQ+eZ2zpu1Ly5mYQ5QzjOBaQ5eCffgBgf8KFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQNN9Prw4XYwnz5b39Sy3XFwtWnaqqmrV+/Nrdtn312oHl9dtW+N63bY1TCZtW1VV69Oe78ert7/UenU53PW5vcI9ebasTz77+M8/1R6+eP2yZaeqavvtcdtWVdXTrzZtW8svf2jb2pyft21NHr7ftlVV9dOrD1t2vvn8050+51dlCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCLTXP0SfDZt6Ov/tvp7llg8evWnZqar67uyobauqanXa91/4j096Lk9UVU0PZ21bNy/O2raqqm6Wdx4X+FuMO75KvXEhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAh0F4nSDrNJ+u+sdm2b6uqtrO+EySbh30nSIbNom3r+vSwbauqatiOrXt38caFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQHvdDhqqaj703PR5MFu17FRVTY8a7xRV1buzvrs3Fy+P27YONm1TdX3c+87ZToeeoR1nvHEhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAh0F4nSKbDpp7MLu7rWW55Mn/bslNVdbzsO3dSVfX28VHf1mrStnXQeMll23fFpaqq1ouenXHHV6k3LgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgTa6wTJ4bCu57Of7+tZbvl1vmzZqap6tPy9bauq6s3Dk7atq9VeX+K/5OBmaNvazsa2raq+kyfjjhdjvHEhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAh0F73KY6GdX102HOC5HI7b9mpqvr+wZO2raqqHx8/aNt6t32vbWtY950g6X7ljEPPyZNxstuONy4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4E2ut20OEwqefT4/t6llu+Prhq2amqOprctG1VVS0X121b7xZ9N5jG68b3QOOZoqqq+emqZWeYuh0E/1nChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDDOO528qCqahiG86p6fX+PA/97L8ZxPLvrQ3uFC/w7+FUZAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAv0BsA535nRvfnYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABURJREFUeJzt3btuHHUYxuFvvD4nERAnUqQkIigChRQUiCINBSU9V0BHyXVQISouggaJko6SIgVIIA4hkQBB7IQQ5+DYu0OBKFx5N+APXvE89Vjv2Nrfjqv5D+M4FpBl6d++AWBxwoVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAy4tc/MzpyXjuwspx3csh++OkZaeqan3Yb9uqqtoc+r4vn4zTtq1fD061be3NFvro/m2nlh+37Nz58XHt3n0yHHXdQr/9uQsr9eHHF5/+rhbw0/5zLTtVVVfXfm7bqqp6ZXW9bevWwW7b1gfbr7dt3Xiw1bZVVfXG1tctO++99flc1/lXGQIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIJFwIt9EL0H+6erbc/eue47uWQ9Z0jX+b+j3n4cs9b6v/y7muftm2dXu57IfqVjb4Xy19a327bqqranfa8xH42zve598SFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQMKFQAsdQbJ2b6xLn+wd170csvrFzZadqqr9Kxfbtqqq3r/9ZtvWq9e+ads6mPU9Bw7GSdtWVdV321stOzt71+e6zhMXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAi10dlDNxlp6Mj2mWzlsunOnZaeqaumznbatqqozl661bV0/f6Ftq4axbWr//lrbVlXV6i+LpfK0xkfznYnkiQuBhAuBhAuBhAuBhAuBhAuBhAuBhAuBhAuBhAuBhAuBhAuBhAuBhAuBhAuBhAuBhAuBhAuBhAuBhAuBhAuBhAuBhAuBhAuBhAuBhAuBFjpXYVweau90z9EPJ1663LJTVTU8eNS2VVU19Jzi8ufW95ttW+vbQ9vW5kHbVFX1na6yNOfv5YkLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgYQLgRY6gmS6NtS9Fxb6kae2f/JMy05V1crurG2rqqr6TuqoZ7/q29q4s9+2NVtu/CNW1f3zPZ/7mvOoE09cCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCLTgESRVv784Pa57OWSy1/edMl2ZtG1VVa0+6Dvy5MSt3batGvqOBXl4fqNtq6rqYLNnZ5zzY++JC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4GEC4EWOjuoZlWThz2tb335qGWnqmp5u/F8naqqWd/ZQdNvb7RtDZO+M5g2Jlfbtqqqfrt8snXvKJ64EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EGgYx3H+i4fhdlXdPL7bgf+958dxPHvURQuFC/w3+FcZAgkXAgkXAgkXAgkXAgkXAgkXAgkXAgkXAv0BWc2OccTfmOIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABLhJREFUeJzt3b+KnFUYwOEz2d1oIoEoLIgSFMVKsPEatLX1HsQ7sLHwFsTCUlsvIzY2Yq8ISSExagxmmd2d+axTZSayJ/42z1Of5f32z+87U+27WpZlAC1XnvUDAPsTLgQJF4KEC0HChSDhQpBwIUi4ECRcCDrc5/DBjZeWw+ObF/Usj7l29WzKnMtus533bj49OZo268rkP4+rf84ZeHL+YJxuTlZPOrdXuIfHN8frX3zy9E+1h/du3Zky51k4Xw6mzfp7/eK0WXd+enXarOt3535YvPXdnL/H23e/3emcj8oQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhaK9/iP7KtUfj43d/uKhnecznxz9OmTPGGAerue+vs2Uzbdbvm5Nps26/+dq0WT+fHk+bNcYYX7/84ZQ56y932wbhxoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4ULQXitItstqnGx2W5HwX52PeWs61tvzabPGGOPB9nTarL+2897Nbx/dmzbr1tH9abPGGOOrGx9MmbMc7HbOjQtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4ULQXruDlrEa6+2c3UH3Nuspc8YYY71MGzXGGGMzVtNmnU18N59e4ntgmfcr28nl/UnDJSZcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCNprBcl2WY31dq8veWoPt/PeKevlYNqs2WauO5npYEzeG7OaPO8J3LgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwI2mufyDLGWG/nrOs4m/hOmb2mY/r6jEvoef8ZunEhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQtNcKku1yZTw6v3pRz8IFmL1eZZb72+tT5x39PeeOW212O+fGhSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIWiv3UHrP14Yv3zzzkU9y2M+ev/TKXPGGGNsJu/XmTluO3HWxO/r8OHBvGFjjLc++37KnN+Wf3Y658aFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFC0GpZlt0Pr1b3xhi/XtzjwHPvjWVZjp90aK9wgf8HH5UhSLgQJFwIEi4ECReChAtBwoUg4UKQcCHoXwb5fyMa9TwIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABR9JREFUeJzt3btuHHUYxuFv9uDdeGNEFDsnoSD6QIGQkGipabhEboSSAlFwCQlCQYpQlIPWju31ULvKTsAfvOJ56onecby/GReW/8M4jgVkmf3bNwBMJ1wIJFwIJFwIJFwIJFwIJFwIJFwIJFwItJhy8cGwGte1ual7uWZYLlt2qqpqvOrbqqq6avxttXnjs3k+b5saZ0PbVlXVsOv5jJxevKrz3el7v7hJ4a5rU18P3374XU2wuP+oZaeqajw7a9uqqhrPL9q2Zrd7HrRVVeOdj9q2rm41PtiravZq27Lz07Mf9rrOj8oQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQaNIfRK/DWzU8+fyGbuW6158ctuxUVS3fXLZtVVUttn17l40nGWwfrtq2Tu/2nmRw8PqoZefyz/3+0Ls3LgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgSadATJuBjq7Hh9U/dyzfZe3zNldbDfsQ//lINl39c2jG1TNTa+BrYP+7aqqt4+7jnyZPfjftd540Ig4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UIg4UKgSWcHXS2H2t6b9E8+2Olxz1ktVVXnR31bVVWb531by23f4UGXq8bv2cdXbVtVVfPjdy0748F+X5c3LgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgSadgTJour0pOeYibMHu5adqqrqO6Wjqqpml/O+red9R3VcbPqOIFmcnLVtVVV9+fi3lp2Xq/O9rvPGhUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUDChUCTjiAZF1Xv7vac1zG7+65lp6pqPu87pqOq6u3usG3rYtP3bD6/0/f/+OTRH21bVVXfHf/asvPz4nSv67xxIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIdC0I0hmVbt1zxEkm8O+I0iO1n1bVVWvlru2rfMHk77Ff8uDO2/atr6//0vbVlXVN+unLTu3h/0+i964EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EGjSwTKzi6r1i57W32xut+xUVV0d9z6/DhaXbVtHt87atr46eda29cXq97atqqrPlj2fx9Xwcq/rvHEhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAh0DCO4/4XD8OLqnp6c7cD/3ufjuN48r6LJoUL/Df4URkCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcC/QUY0n6iCl+3KgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABSFJREFUeJzt3b1uHAUUhuEzu95dx0nk/GAJIkgQPQ0SNVfDvXETlBGiQIAoqJESAokIIT82sb07VClcZYdkD3zwPPVI38j263XlM4zjWECW2T/9AsB0woVAwoVAwoVAwoVAwoVAwoVAwoVAwoVAe1MePri+HK/dOtjVu1xwvF627FRVnZwu2raqquq87/flsG6bqtlZ39beyaZvrKrq+UnLzJ/1ok7Hl8PrnpsU7rVbB/X5F5/9/bea4Jsnt1t2qqp+vP9u21ZV1ebhftvW4ulrfwbemku/9G0dfX/ctlVVNdz9rmXn6/HLrZ7zpzIEEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EEi4EmvQP0RfDut5bPtnVu1xwtLrRslNVde9Kz3+pf+X3k0lf9jdyvu7bOr7VNlUP93ouarxy/eqnLTvj3a+2es4nLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgSadJ9irKHOxvmu3uWCG8sXLTtVVTcvH7dtVVX98bTvfMZm1fP9qqra9F07qdOj876xqnp+p+frePrDsNVzPnEhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAhkHAh0MTbQdV2O+j26nHLTlXVy8PGozdV9euzK21bzzfb3aJ5G4ZhbNtarnpvB83f2bTszFbr7Z7b8XsAOyBcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCCRcCDTp9sZyWNcHi57TIPuz05adqqrV7Kxtq6rq55uHbVv3ltfatjpdXvb9fFRVLWbbnQZ5U/fnTpDAf5ZwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIdCkEySXhrP6ePVgV+9ywdnY9ztlf+g9QfLJ4dW2revLk7atl5t529alee/3bD6MLTvfzs+3es4nLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgSadIJkOQz1/nyxq3e54PHmtGWnqupZ41ZV1Uerh21bh3vHbVtnY98Jknn1nAR5ZV1Dy87+bLvTKj5xIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIZBwIdCk20GzGupgttzVu1zwYN13z+e3zeW2raqqxbBu2/pw+ahtaz32fQ7Mh03bVlXfraL9we0g+M8SLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQSLgQaxnH70wrDMDyqqp929zrwv3dnHMej1z00KVzg38GfyhBIuBBIuBBIuBBIuBBIuBBIuBBIuBBIuBDoL9TIh3Qb70jQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualzing the feature map for the bad images\n",
    "\n",
    "vis_obj = VisualizeActivation(17,model)\n",
    "j = 0\n",
    "for i in imgs_path_bad:\n",
    "    if(j==5):\n",
    "        break\n",
    "    else:\n",
    "        j+=1\n",
    "        img_test = plt.imread(i)\n",
    "        img_test = cv2.resize(img_test, (img_size, img_size))\n",
    "        img_test_ = np.reshape(img_test, (1, img_test.shape[0], img_test.shape[1], img_test.shape[2]))\n",
    "        vis_obj.visualize_feature_maps(img_test_)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 128, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(img_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 15s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6082744002342224, 0.699999988079071]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation on the test set\n",
    "model.evaluate(x_test2, y_test_2, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_analysis(tp,fp,fn,tn):\n",
    "    accuracy = (tp + tn)/(tp + tn + fn + fp)\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    ppv = tp/(tp+fp)\n",
    "    npv = tn/(tn+fn)\n",
    "    print(\"---accuracy---       \", accuracy)\n",
    "    print(\"---sensitivity---    \", sensitivity)\n",
    "    print(\"---specificity---    \", specificity)\n",
    "    print(\"---pos pred value--- \", ppv)\n",
    "    print(\"---neg pred value--- \", npv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---accuracy---        0.7\n",
      "---sensitivity---     1.0\n",
      "---specificity---     0.1\n",
      "---pos pred value---  0.6896551724137931\n",
      "---neg pred value---  1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i]<0.5:\n",
    "        y_pred[i]=0\n",
    "    else:\n",
    "        y_pred[i]=1\n",
    "\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "true_positives = 0\n",
    "true_negatives = 0\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if(y_pred[i]==y_test_2[i] and y_test_2[i] == 0):\n",
    "        true_positives+=1\n",
    "    if(y_pred[i]==y_test_2[i] and y_test_2[i] == 1):\n",
    "        true_negatives+=1\n",
    "    if(y_pred[i]!=y_test_2[i] and y_test_2[i] == 0):\n",
    "        false_negatives+=1\n",
    "    if(y_pred[i]!=y_test_2[i] and y_test_2[i] == 1):\n",
    "        false_positives+=1\n",
    "\n",
    "data_analysis(true_positives, false_positives, false_negatives, true_negatives)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### accuracy is 70%\n",
    "#### sensitivity is 100 % i.e percentage of positive values that should have been predicted positive\n",
    "#### specificity is 10% i.e percentage of negative values that should have been predicted negative. This means that for smaller image size, more bad images are predicted as good images\n",
    "#### positive predictive value is 68.9% -  probability that the sample that returns a positive result really is positive\n",
    "#### negative predicted value is 100% - probability that the sample that returns a negative result really is negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_with(lr):\n",
    "\n",
    "    obj = EyeCalc(Input(shape=(img_size, img_size, 3)))\n",
    "    model = obj.build_model()\n",
    "    model.summary()\n",
    "    optimizer = Adam(lr=lr)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    # Evaluate the model with the eval dataset.\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    epochs=1, validation_data=(x_val, y_val), callbacks=callbacks_list, steps_per_epoch=100)\n",
    "   \n",
    "\n",
    "    score = model.evaluate(x_test2,y_test_2, steps=10, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    # Return the accuracy.\n",
    "\n",
    "    return score[1]\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "verbose = 1\n",
    "fit_with_partial = partial(fit_with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "    pbounds = {'lr': (1e-4, 1e-2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    lr     |\n",
      "-------------------------------------\n",
      "<class 'numpy.int64'>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 8, 8, 1)           513       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 8, 8, 1)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "swap_3 (SWAP)                (None, 1)                 64        \n",
      "=================================================================\n",
      "Total params: 1,555,393\n",
      "Trainable params: 1,553,473\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 147s 1s/step - loss: 3.4655 - acc: 0.5359 - val_loss: 12.0942 - val_acc: 0.2414\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.79661\n",
      "Test loss: 10.628256797790527\n",
      "Test accuracy: 0.3333333432674408\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.3333  \u001b[0m | \u001b[0m 0.004229\u001b[0m |\n",
      "<class 'numpy.int64'>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 8, 8, 1)           513       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 8, 8, 1)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "swap_4 (SWAP)                (None, 1)                 64        \n",
      "=================================================================\n",
      "Total params: 1,555,393\n",
      "Trainable params: 1,553,473\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      " 66/100 [==================>...........] - ETA: 52s - loss: 4.1883 - acc: 0.5022"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/dl_env_3.5/lib/python3.5/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0.007231212485077366,)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-21cb34ca9ee3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dl_env_3.5/lib/python3.5/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTMIZATION_END\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dl_env_3.5/lib/python3.5/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dl_env_3.5/lib/python3.5/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-84-6c7522f58c5a>\u001b[0m in \u001b[0;36mfit_with\u001b[0;34m(lr)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Evaluate the model with the eval dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n\u001b[0;32m---> 12\u001b[0;31m                     epochs=1, validation_data=(x_val, y_val), callbacks=callbacks_list, steps_per_epoch=100)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dl_env_3.5/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dl_env_3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dl_env_3.5/lib/python3.5/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dl_env_3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dl_env_3.5/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dl_env_3.5/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dl_env_3.5/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = BayesianOptimization(\n",
    "    f=fit_with_partial,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer.maximize(init_points=10, n_iter=10,)\n",
    "\n",
    "\n",
    "for i, res in enumerate(optimizer.res):\n",
    "    print(\"Iteration {}: \\n\\t{}\".format(i, res))\n",
    "\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the hyperparamter optimization code takes a lot of time on my CPU. Therefore, the process was stopped in between. Basically I have tried to implement Bayesian optimization. I could have gone for Random Search or Grid Search but that would have taken a longer time. Moreover, they are more random in their approach. Bayesian technique will try to take a calculative step for the next hyperparameter value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
